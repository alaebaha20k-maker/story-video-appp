{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ¬ AI Video Generator - ASYNC VERSION (No Timeouts!)\n",
        "\n",
        "## âœ… ZERO CONFIGURATION NEEDED!\n",
        "\n",
        "**How it works:**\n",
        "1. Backend sends job â†’ Gets job_id instantly âš¡\n",
        "2. Colab processes in background (keeps session alive) ğŸ”„\n",
        "3. Backend polls status every 10s ğŸ“Š\n",
        "4. When done, downloads video âœ…\n",
        "5. **NO NGROK TIMEOUTS!** ğŸ‰\n",
        "\n",
        "**Just run cells 1â†’2â†’3â†’4â†’5â†’6â†’7 in order!**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 1: INSTALL EVERYTHING\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import sys\n",
        "print(f\"Python: {sys.version}\\n\")\n",
        "\n",
        "if sys.version_info >= (3, 12):\n",
        "    print(\"Installing Python 3.10...\")\n",
        "    !pip install -q condacolab\n",
        "    import condacolab\n",
        "    condacolab.install()\n",
        "    print(\"âš ï¸  Runtime restarting - Run this cell again after restart!\")\n",
        "else:\n",
        "    print(\"Installing packages...\\n\")\n",
        "    !apt-get update -qq && apt-get install -y -qq ffmpeg\n",
        "    !pip install -q flask flask-cors pyngrok requests torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "    !pip install -q TTS soundfile numpy scipy diffusers transformers accelerate safetensors pillow opencv-python-headless\n",
        "    print(\"\\nâœ… All installed! Run Cell 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 2: IMPORTS (Auto-install if missing)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import sys, subprocess\n",
        "\n",
        "def check(pkg, imp=None):\n",
        "    try: __import__(imp or pkg.replace('-','_'))\n",
        "    except: subprocess.run([sys.executable,'-m','pip','install','-q',pkg]); print(f\"Installed {pkg}\")\n",
        "\n",
        "check('flask'); check('flask-cors','flask_cors'); check('pyngrok'); check('torch'); check('pillow','PIL')\n",
        "\n",
        "import torch, json, io, gc, time, base64\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "from flask_cors import CORS\n",
        "from pyngrok import ngrok\n",
        "from threading import Thread\n",
        "from datetime import datetime\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if device=='cuda' else 'None'}\")\n",
        "\n",
        "output_dir = Path('/content/outputs')\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "print(\"âœ… Ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 3: IMAGE MODEL (Auto-install)\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import sys, subprocess\n",
        "try: from diffusers import StableDiffusionXLPipeline\n",
        "except: subprocess.run([sys.executable,'-m','pip','install','-q','diffusers','transformers','accelerate']); from diffusers import StableDiffusionXLPipeline\n",
        "\n",
        "img_pipeline = None\n",
        "STYLES = {\"cinematic\":{\"p\":\"cinematic, movie quality\",\"n\":\"low quality\"},\"anime\":{\"p\":\"anime style, manga\",\"n\":\"photorealistic\"},\"horror\":{\"p\":\"dark, creepy, terrifying\",\"n\":\"bright, cheerful\"}}\n",
        "\n",
        "def load_img():\n",
        "    global img_pipeline\n",
        "    if not img_pipeline:\n",
        "        print(\"Loading DreamShaper XL...\")\n",
        "        img_pipeline = StableDiffusionXLPipeline.from_pretrained(\"Lykon/dreamshaper-xl-1-0\",torch_dtype=torch.float16,variant=\"fp16\").to(device)\n",
        "        img_pipeline.enable_xformers_memory_efficient_attention()\n",
        "    return img_pipeline\n",
        "\n",
        "def gen_img(prompt, style=\"cinematic\"):\n",
        "    p = load_img()\n",
        "    s = STYLES.get(style, STYLES[\"cinematic\"])\n",
        "    return p(prompt=f\"{prompt}, {s['p']}\", negative_prompt=s['n'], num_inference_steps=25, height=864, width=1536).images[0]\n",
        "\n",
        "print(\"âœ… Image ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 4: VOICE MAPPING + TTS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "VOICES = {'guy':'p226','adam':'p226','brian':'p227','aria':'p229','sarah':'p231','nicole':'p233','jenny':'p228','emma':'p230'}\n",
        "def get_voice(v): return VOICES.get(v,'p226')\n",
        "\n",
        "import sys, subprocess\n",
        "try: import TTS\n",
        "except:\n",
        "    if sys.version_info >= (3, 12):\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'coqui-tts', 'soundfile'], check=True)\n",
        "    else:\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'TTS', 'soundfile'], check=True)\n",
        "\n",
        "tts_model = None\n",
        "\n",
        "def load_tts():\n",
        "    global tts_model\n",
        "    if not tts_model:\n",
        "        from TTS.api import TTS as TTSModel\n",
        "        print(\"Loading TTS model...\")\n",
        "        tts_model = TTSModel(\"tts_models/en/vctk/vits\").to(device)\n",
        "    return tts_model\n",
        "\n",
        "def gen_voice(text, voice, path):\n",
        "    load_tts().tts_to_file(text=text, speaker=get_voice(voice), file_path=path)\n",
        "    return path\n",
        "\n",
        "print(\"âœ… TTS ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 5: ASYNC JOB QUEUE SYSTEM\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# Job storage: {job_id: {status, progress, video_path, error, created_at}}\n",
        "jobs = {}\n",
        "\n",
        "def process_video_job(job_id, data):\n",
        "    \"\"\"Process video generation in background thread\"\"\"\n",
        "    try:\n",
        "        jobs[job_id]['status'] = 'processing'\n",
        "        jobs[job_id]['progress'] = 0\n",
        "        \n",
        "        wd = output_dir / job_id\n",
        "        wd.mkdir(exist_ok=True)\n",
        "        \n",
        "        # Generate images\n",
        "        image_prompts = data.get('image_prompts', [])\n",
        "        style = data.get('style', 'cinematic')\n",
        "        \n",
        "        print(f\"[{job_id}] Generating {len(image_prompts)} images...\")\n",
        "        for i, prompt in enumerate(image_prompts):\n",
        "            img = gen_img(prompt, style)\n",
        "            img.save(wd / f\"{i:04d}.png\")\n",
        "            jobs[job_id]['progress'] = int((i + 1) / len(image_prompts) * 40)  # 0-40%\n",
        "            print(f\"[{job_id}] Image {i+1}/{len(image_prompts)} done ({jobs[job_id]['progress']}%)\")\n",
        "        \n",
        "        # Generate voice\n",
        "        print(f\"[{job_id}] Generating voice...\")\n",
        "        jobs[job_id]['progress'] = 50\n",
        "        ap = wd / \"voice.wav\"\n",
        "        gen_voice(data.get('script', ''), data.get('voice', 'aria'), str(ap))\n",
        "        jobs[job_id]['progress'] = 70\n",
        "        \n",
        "        # Compile video\n",
        "        print(f\"[{job_id}] Compiling video...\")\n",
        "        jobs[job_id]['progress'] = 80\n",
        "        op = wd / \"final.mp4\"\n",
        "        \n",
        "        subprocess.run([\n",
        "            'ffmpeg', '-y', '-hwaccel', 'cuda',\n",
        "            '-framerate', '30',\n",
        "            '-pattern_type', 'glob',\n",
        "            '-i', str(wd / '*.png'),\n",
        "            '-i', str(ap),\n",
        "            '-c:v', 'h264_nvenc',\n",
        "            '-b:v', '10M',\n",
        "            '-c:a', 'aac',\n",
        "            '-s', '1920x1080',\n",
        "            str(op)\n",
        "        ], check=True, capture_output=True)\n",
        "        \n",
        "        # Complete\n",
        "        jobs[job_id]['status'] = 'completed'\n",
        "        jobs[job_id]['progress'] = 100\n",
        "        jobs[job_id]['video_path'] = str(op)\n",
        "        print(f\"[{job_id}] âœ… COMPLETED!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        jobs[job_id]['status'] = 'failed'\n",
        "        jobs[job_id]['error'] = str(e)\n",
        "        print(f\"[{job_id}] âŒ FAILED: {e}\")\n",
        "\n",
        "print(\"âœ… Job queue ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 6: FLASK SERVER WITH ASYNC ENDPOINTS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/health')\n",
        "def health():\n",
        "    return jsonify({\"ok\": True, \"gpu\": device=='cuda', \"active_jobs\": len([j for j in jobs.values() if j['status'] == 'processing'])})\n",
        "\n",
        "@app.route('/submit_job', methods=['POST'])\n",
        "def submit_job():\n",
        "    \"\"\"Submit video generation job - returns job_id immediately\"\"\"\n",
        "    try:\n",
        "        data = request.get_json(force=True)\n",
        "        \n",
        "        import uuid\n",
        "        job_id = str(uuid.uuid4())\n",
        "        \n",
        "        # Create job entry\n",
        "        jobs[job_id] = {\n",
        "            'status': 'queued',\n",
        "            'progress': 0,\n",
        "            'video_path': None,\n",
        "            'error': None,\n",
        "            'created_at': datetime.now().isoformat()\n",
        "        }\n",
        "        \n",
        "        # Start background processing\n",
        "        Thread(target=process_video_job, args=(job_id, data), daemon=True).start()\n",
        "        \n",
        "        print(f\"\\nğŸš€ Job {job_id} submitted!\")\n",
        "        \n",
        "        return jsonify({\n",
        "            \"success\": True,\n",
        "            \"job_id\": job_id,\n",
        "            \"message\": \"Job queued - check /job_status/<job_id> for progress\"\n",
        "        })\n",
        "        \n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "@app.route('/job_status/<job_id>')\n",
        "def job_status(job_id):\n",
        "    \"\"\"Check job status and progress\"\"\"\n",
        "    if job_id not in jobs:\n",
        "        return jsonify({\"error\": \"Job not found\"}), 404\n",
        "    \n",
        "    job = jobs[job_id]\n",
        "    return jsonify({\n",
        "        \"job_id\": job_id,\n",
        "        \"status\": job['status'],\n",
        "        \"progress\": job['progress'],\n",
        "        \"error\": job.get('error'),\n",
        "        \"created_at\": job.get('created_at')\n",
        "    })\n",
        "\n",
        "@app.route('/download/<job_id>')\n",
        "def download(job_id):\n",
        "    \"\"\"Download completed video\"\"\"\n",
        "    if job_id not in jobs:\n",
        "        return jsonify({\"error\": \"Job not found\"}), 404\n",
        "    \n",
        "    job = jobs[job_id]\n",
        "    \n",
        "    if job['status'] != 'completed':\n",
        "        return jsonify({\"error\": f\"Job not completed (status: {job['status']})\"}), 400\n",
        "    \n",
        "    video_path = Path(job['video_path'])\n",
        "    if not video_path.exists():\n",
        "        return jsonify({\"error\": \"Video file not found\"}), 404\n",
        "    \n",
        "    return send_file(str(video_path), mimetype='video/mp4')\n",
        "\n",
        "print(\"âœ… Server ready with async endpoints\")\n",
        "print(\"   POST /submit_job â†’ Get job_id instantly\")\n",
        "print(\"   GET /job_status/<job_id> â†’ Check progress\")\n",
        "print(\"   GET /download/<job_id> â†’ Download video\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CELL 7: START SERVER\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "YOUR_NGROK_TOKEN = \"35HuufK0IT26RER84mcvIbRjrog_7grjZvuDXtRPYL5hWLNCK\"\n",
        "\n",
        "# Start ngrok tunnel\n",
        "ngrok.set_auth_token(YOUR_NGROK_TOKEN)\n",
        "url = ngrok.connect(5001)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(f\"ğŸŒ ASYNC SERVER RUNNING AT: {url}\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Add this to your backend config/__init__.py:\")\n",
        "print(f\"COLAB_SERVER_URL = '{url}'\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nğŸ“‹ API Endpoints:\")\n",
        "print(f\"   Health: {url}/health\")\n",
        "print(f\"   Submit Job: {url}/submit_job (POST)\")\n",
        "print(f\"   Job Status: {url}/job_status/<job_id> (GET)\")\n",
        "print(f\"   Download: {url}/download/<job_id> (GET)\")\n",
        "print(\"\\nğŸ”¥ NO MORE TIMEOUT ISSUES!\")\n",
        "print(\"   Jobs process in background while ngrok stays alive!\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Start Flask server\n",
        "try:\n",
        "    app.run(host='0.0.0.0', port=5001, debug=False, use_reloader=False)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nâœ… Server stopped\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
