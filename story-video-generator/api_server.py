"""
ğŸ”Œ API SERVER - With Kokoro TTS (PRIMARY) + Edge-TTS (BACKUP)
"""

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from pathlib import Path
import os
import threading
import re
from pydub import AudioSegment
import asyncio
import edge_tts

# âœ… IMPORTS FOR TEMPLATES + RESEARCH
from src.ai.script_analyzer import script_analyzer
from src.research.fact_searcher import fact_searcher
from src.ai.enhanced_script_generator import enhanced_script_generator

# âœ… EXISTING IMPORTS
from src.ai.image_generator import create_image_generator
from src.editor.ffmpeg_compiler import FFmpegCompiler

app = Flask(__name__)

# CORS for all origins
CORS(app, resources={
    r"/*": {
        "origins": "*",
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type"]
    }
})

progress_state = {
    'status': 'ready',
    'progress': 0,
    'video_path': None,
    'error': None,
    'voice_engine': None,
    'voice_id': None,
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¤ EDGE-TTS - FREE, RELIABLE, ALWAYS WORKS!
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print(f"\nğŸ”§ Using Edge-TTS (Microsoft) - FREE & UNLIMITED!")
print("âœ… Edge-TTS ready - No API key needed!")
print("   ğŸ’° FREE & UNLIMITED forever!")
print("   ğŸ¬ 10+ professional voices!")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HELPER FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def sanitize_filename(filename):
    """Clean filename"""
    filename = re.sub(r'[^a-zA-Z0-9_\-]', '', filename)
    filename = re.sub(r'_+', '_', filename)
    return filename[:50]


def get_voice_id(voice_id=None):
    """Get Edge-TTS voice ID"""
    
    # âœ… Map to Edge-TTS voices (Microsoft)
    voice_map = {
        # Male voices
        'guy': 'en-US-GuyNeural',
        'andrew': 'en-US-AndrewNeural',
        'brian': 'en-US-BrianNeural',
        'christopher': 'en-US-ChristopherNeural',
        'roger': 'en-US-RogerNeural',
        
        # Female voices
        'aria': 'en-US-AriaNeural',
        'jenny': 'en-US-JennyNeural',
        'sara': 'en-US-SaraNeural',
        'nancy': 'en-US-NancyNeural',
        'michelle': 'en-US-MichelleNeural',
        
        # Old mappings
        'matthew': 'en-US-GuyNeural',
        'joey': 'en-US-ChristopherNeural',
        'justin': 'en-US-RogerNeural',
        'joanna': 'en-US-AriaNeural',
        'salli': 'en-US-JennyNeural',
        'kimberly': 'en-US-SaraNeural',
        'ivy': 'en-US-NancyNeural',
    }
    
    # Use mapping or default
    if voice_id:
        voice_id = voice_map.get(voice_id.lower() if isinstance(voice_id, str) else 'en-US-GuyNeural', 'en-US-GuyNeural')
    else:
        voice_id = 'en-US-GuyNeural'  # Default male voice
    
    print(f"   ğŸ”§ Voice for Edge-TTS: {voice_id}")
    return voice_id


def generate_audio_edge(text, voice="en-US-GuyNeural", output_path="narration.mp3"):
    """âœ… Generate audio using Edge-TTS - FREE, RELIABLE, ALWAYS WORKS!"""
    print(f"\nğŸ¤ Generating audio with Edge-TTS (Microsoft - FREE!)...")
    print(f"   Voice: {voice}")
    print(f"   Text length: {len(text)} characters")
    print(f"   Output path: {output_path}")
    print(f"   ğŸ’° Cost: $0 (FREE!)")
    
    try:
        # Generate with Edge-TTS
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        audio_path = loop.run_until_complete(
            generate_audio_edge_tts(text, voice, output_path)
        )
        loop.close()
        
        print(f"âœ… Edge-TTS generation SUCCESS!")
        print(f"   ğŸ¬ Good quality for YouTube - FREE forever!")
        return audio_path
        
    except Exception as e:
        print(f"\n{'='*60}")
        print(f"âŒ EDGE-TTS GENERATION FAILED!")
        print(f"{'='*60}")
        print(f"Error: {e}")
        print(f"Voice: {voice}")
        print(f"Text length: {len(text)}")
        print(f"\nğŸ’¡ Troubleshooting:")
        print(f"   1. Check internet connection")
        print(f"   2. Try a different voice")
        print(f"   3. Check text length")
        print(f"{'='*60}\n")
        raise


async def generate_audio_edge_tts(text, voice="en-US-GuyNeural", output_path="narration.mp3"):
    """âœ… Edge-TTS fallback - Always works!"""
    from pydub import AudioSegment
    
    print(f"   ğŸ¤ Edge-TTS generating...")
    
    # For long text, use chunking
    if len(text) > 3000:
        chunks = _split_text_smart(text, max_chars=2000)
        print(f"   Split into {len(chunks)} chunks for Edge-TTS")
        
        temp_dir = Path("output/temp/edge_chunks")
        temp_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate chunks in parallel
        tasks = []
        chunk_files = []
        
        for i, chunk in enumerate(chunks):
            chunk_file = temp_dir / f"chunk_{i:03d}.mp3"
            chunk_files.append(chunk_file)
            communicate = edge_tts.Communicate(chunk, voice, rate="+10%")
            tasks.append(communicate.save(str(chunk_file)))
        
        await asyncio.gather(*tasks)
        
        # Combine chunks
        combined = AudioSegment.empty()
        for chunk_file in chunk_files:
            if chunk_file.exists():
                audio_chunk = AudioSegment.from_mp3(str(chunk_file))
                combined += audio_chunk
                chunk_file.unlink()
        
        combined.export(str(output_path), format="mp3", bitrate="192k")
    else:
        # Short text - generate directly
        communicate = edge_tts.Communicate(text, voice, rate="+10%")
        await communicate.save(str(output_path))
    
    return str(output_path)


def _split_text_smart(text, max_chars=2000):
    """Split text at sentence boundaries"""
    sentences = text.replace('!', '.').replace('?', '.').split('.')
    sentences = [s.strip() + '.' for s in sentences if s.strip()]
    
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk) + len(sentence) <= max_chars:
            current_chunk += " " + sentence
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = sentence
    
    if current_chunk:
        chunks.append(current_chunk.strip())
    
    return chunks if chunks else [text]


def get_audio_duration(audio_path):
    """Get duration of audio file (MP3 or WAV)"""
    try:
        audio_path = str(audio_path)

        if audio_path.endswith('.mp3'):
            audio = AudioSegment.from_mp3(audio_path)
        elif audio_path.endswith('.wav'):
            audio = AudioSegment.from_wav(audio_path)
        else:
            # Try to detect format
            audio = AudioSegment.from_file(audio_path)
        
        duration = len(audio) / 1000.0  # Convert to seconds
        return duration
    except Exception as e:
        print(f"âŒ Error reading audio: {e}")
        return 5.0  # Fallback


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BACKGROUND FUNCTIONS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_video_background(data):
    """Original video generation (without template)"""
    global progress_state

    try:
        print(f"\nğŸ¬ Starting generation: {data.get('topic', 'Untitled')}")
        
        # Get voice from user (Edge-TTS only)
        voice_id = get_voice_id(data.get('voice_id'))
        zoom_effect = data.get('zoom_effect', True)
        
        print(f"ğŸ¤ Voice Engine: EDGE-TTS (Microsoft)")
        print(f"ğŸ¤ Voice ID: {voice_id}")
        print(f"ğŸ¬ Zoom Effect: {'ENABLED' if zoom_effect else 'DISABLED'}")
        
        # Update progress state
        progress_state['voice_engine'] = 'edge'
        progress_state['voice_id'] = voice_id
        
        # Script
        progress_state['status'] = 'Generating script...'
        progress_state['progress'] = 10
        print("ğŸ“ Step 1/4: Generating script...")
        
        # ğŸ“ Generate script with Gemini (10/10 quality with improved prompts!)
        result = enhanced_script_generator.generate_with_template(
            topic=data.get('topic', 'Test Story'),
            story_type=data.get('story_type', 'scary_horror'),
            template=None,  # No template
            research_data=None,  # No research
            duration_minutes=int(data.get('duration', 5)),
            num_scenes=int(data.get('num_scenes', 10))  # âœ… User selection!
        )
        
        print(f"   âœ… Script: {len(result['script'])} characters")
        
        # Images
        progress_state['status'] = 'Generating images...'
        progress_state['progress'] = 30
        print("ğŸ¨ Step 2/4: Generating images...")
        
        image_gen = create_image_generator(
            data.get('image_style', 'cinematic_film'), 
            data.get('story_type', 'scary_horror')
        )
        characters = {char: f"{char}, character" for char in result.get('characters', [])[:3]}
        images = image_gen.generate_batch(result['scenes'], characters)
        image_paths = [Path(img['filepath']) for img in images if img]
        
        print(f"   âœ… Images: {len(image_paths)} generated")
        print(f"   ğŸ” DEBUG: Image paths:")
        for i, img_path in enumerate(image_paths):
            exists = "EXISTS" if img_path.exists() else "MISSING!"
            print(f"      Image {i+1}: {img_path.name} - {exists}")
        
        # Voice Generation - Edge-TTS
        progress_state['status'] = 'Generating voice with Edge-TTS...'
        progress_state['progress'] = 60
        print(f"ğŸ¤ Step 3/4: Generating voice with Edge-TTS (FREE!)...")
        
        audio_path = Path("output/temp/narration.mp3")
        audio_path.parent.mkdir(parents=True, exist_ok=True)
        
        # âœ… EDGE-TTS - FREE & UNLIMITED!
        generate_audio_edge(
            text=result['script'],
            voice=voice_id,
            output_path=str(audio_path)
        )
        
        audio_duration = get_audio_duration(audio_path)
        print(f"   âœ… Audio: {audio_duration:.1f} seconds ({audio_duration/60:.1f} minutes)")
        
        # Calculate durations - MATCH VIDEO TO AUDIO!
        time_per_image = audio_duration / len(image_paths) if image_paths else 5
        durations = [time_per_image] * len(image_paths)
        
        # Debug: Show calculation
        print(f"   ğŸ”§ Image timing:")
        print(f"      Images: {len(image_paths)}")
        print(f"      Duration per image: {time_per_image:.1f}s")
        print(f"      Total video duration: {sum(durations):.1f}s ({sum(durations)/60:.1f} minutes)")
        
        # Video
        progress_state['status'] = 'Compiling video...'
        progress_state['progress'] = 80
        print("ğŸ¬ Step 4/4: Compiling video...")

        compiler = FFmpegCompiler()
        safe_topic = sanitize_filename(data.get('topic', 'video'))
        output_filename = f"{safe_topic}_video.mp4"

        video_path = compiler.create_video(
            image_paths,
            str(audio_path),
            Path(f"output/videos/{output_filename}"),
            durations,
            zoom_effect=zoom_effect
        )
        
        progress_state['progress'] = 100
        progress_state['status'] = 'complete'
        progress_state['video_path'] = output_filename

        print(f"\nâœ… SUCCESS! Video: {output_filename}")
        print(f"   Voice Engine: Edge-TTS (Microsoft)")
        print(f"   Voice: {voice_id}")
        print(f"   Zoom Effect: {'ENABLED' if zoom_effect else 'DISABLED'}\n")
        
    except Exception as e:
        progress_state['status'] = 'error'
        progress_state['error'] = str(e)
        print(f"\nâŒ ERROR: {e}\n")
        import traceback
        traceback.print_exc()


def generate_with_template_background(topic, story_type, template, research_data, duration, num_scenes, voice_engine, voice_id, voice_speed=1.0,
zoom_effect=True):
    """âœ… Background generation with template + research + voice selection + zoom effect"""
    global progress_state

    try:
        progress_state['status'] = 'generating'
        progress_state['progress'] = 10
        
        # Get voice (Edge-TTS only)
        voice_id = get_voice_id(voice_id)
        progress_state['voice_engine'] = 'edge'
        progress_state['voice_id'] = voice_id

        print(f"ğŸ“ Generating script with template...")
        print(f"ğŸ¤ Voice Engine: EDGE-TTS (Microsoft)")
        print(f"ğŸ¤ Voice: {voice_id}")
        print(f"ğŸ¬ Zoom Effect: {'ENABLED' if zoom_effect else 'DISABLED'}")
        
        # ğŸ“ Generate script with Gemini (improved prompts!)
        result = enhanced_script_generator.generate_with_template(
            topic=topic,
            story_type=story_type,
            template=template,
            research_data=research_data,
            duration_minutes=duration,
            num_scenes=num_scenes
        )

        script_text = result['script']

        progress_state['progress'] = 50
        progress_state['status'] = 'generating_images'

        print("ğŸ¨ Generating images...")
        
        # âœ… FIX: Use scenes from result if available (MUCH BETTER VARIETY!)
        if 'scenes' in result and result['scenes']:
            # Use the structured scenes from script generator - BEST QUALITY!
            scenes = result['scenes'][:num_scenes]
            print(f"   Using {len(scenes)} varied scenes from script generator")
        else:
            # Fallback: Extract image prompts from script
            image_prompts = re.findall(r'IMAGE:\s*(.+?)(?:\n|$)', script_text, re.IGNORECASE)
            
            if not image_prompts or len(image_prompts) < num_scenes:
                # Create VARIED prompts based on story progression
                print(f"   âš ï¸  Creating varied prompts (no scenes in result)")
                story_parts = script_text.split('.')[:num_scenes]
                image_prompts = []
                for i, part in enumerate(story_parts):
                    if part.strip():
                        # Use actual story content for variety!
                        image_prompts.append(f"{part.strip()[:100]}")
                    else:
                        image_prompts.append(f"{topic}, scene {i+1}, {story_type} atmosphere")
            
            # Convert string prompts to scene dictionaries
            scenes = []
            for i, prompt in enumerate(image_prompts[:num_scenes]):
                scenes.append({
                    'image_description': prompt,
                    'content': prompt,
                    'scene_number': i + 1
                })
        
        # Generate images
        image_gen = create_image_generator('cinematic_film', story_type)
        characters = {char: f"{char}, character" for char in result.get('characters', [])[:3]}
        images = image_gen.generate_batch(scenes, characters)
        image_paths = [Path(img['filepath']) for img in images if img]

        print(f"âœ… Generated {len(image_paths)} images")
        print(f"   ğŸ” DEBUG: Image paths:")
        for i, img_path in enumerate(image_paths):
            exists = "EXISTS" if img_path.exists() else "MISSING!"
            print(f"      Image {i+1}: {img_path.name} - {exists}")
        
        progress_state['progress'] = 70
        progress_state['status'] = 'generating_voice_edge'
        
        print(f"ğŸ¤ Generating voice with Edge-TTS (FREE!)...")
        
        # Generate audio with Edge-TTS
        audio_path = Path("output/temp/narration.mp3")
        audio_path.parent.mkdir(parents=True, exist_ok=True)
        
        # âœ… EDGE-TTS - FREE & UNLIMITED!
        generate_audio_edge(
            text=script_text,
            voice=voice_id,
            output_path=str(audio_path)
        )
        
        audio_duration = get_audio_duration(audio_path)
        print(f"âœ… Audio: {audio_duration:.1f} seconds ({audio_duration/60:.1f} minutes)")
        
        progress_state['progress'] = 80
        progress_state['status'] = 'compiling_video'

        print("ğŸ¬ Compiling video...")

        # Compile video
        compiler = FFmpegCompiler()
        safe_topic = re.sub(r'[^a-zA-Z0-9_\-]', '', topic)[:50]
        output_filename = f"{safe_topic}_video.mp4"

        time_per_image = audio_duration / len(image_paths) if image_paths else 5
        durations = [time_per_image] * len(image_paths)

        video_path = compiler.create_video(
            image_paths,
            str(audio_path),
            Path(f"output/videos/{output_filename}"),
            durations,
            zoom_effect=zoom_effect
        )

        progress_state['progress'] = 100
        progress_state['status'] = 'complete'
        progress_state['video_path'] = output_filename

        print(f"\nâœ… SUCCESS!")
        print(f"   Video: {output_filename}")
        print(f"   Script: {len(script_text)} chars")
        print(f"   Voice Engine: Edge-TTS (Microsoft)")
        print(f"   Voice: {voice_id}")
        print(f"   Zoom Effect: {'ENABLED' if zoom_effect else 'DISABLED'}")
        print(f"   Template: {'Used' if template else 'Not used'}")
        print(f"   Research: {'Used' if research_data else 'Not used'}\n")

    except Exception as e:
        progress_state['status'] = 'error'
        progress_state['error'] = str(e)
        print(f"\nâŒ ERROR: {e}\n")
        import traceback
        traceback.print_exc()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# API ROUTES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/health', methods=['GET', 'OPTIONS'])
def health():
    if request.method == 'OPTIONS':
        return '', 204
    return jsonify({
        'status': 'ok',
        'message': 'API Server running',
        'voice_engine': 'edge_tts',
        'script_engine': 'gemini_ai'
    }), 200


@app.route('/api/voices', methods=['GET', 'OPTIONS'])
def list_voices():
    """âœ… List all available Edge-TTS voices"""
    if request.method == 'OPTIONS':
        return '', 204
    
    # Edge-TTS voices (Microsoft)
    voices = {
        'guy': {'engine': 'edge', 'name': 'Guy', 'gender': 'male', 'style': 'Natural & Clear', 'best_for': 'General narration'},
        'andrew': {'engine': 'edge', 'name': 'Andrew', 'gender': 'male', 'style': 'Professional', 'best_for': 'Business content'},
        'christopher': {'engine': 'edge', 'name': 'Christopher', 'gender': 'male', 'style': 'Casual & Friendly', 'best_for': 'Vlogs, tutorials'},
        'roger': {'engine': 'edge', 'name': 'Roger', 'gender': 'male', 'style': 'Authoritative', 'best_for': 'News, documentaries'},
        'aria': {'engine': 'edge', 'name': 'Aria', 'gender': 'female', 'style': 'Natural & Warm', 'best_for': 'Stories, lifestyle'},
        'jenny': {'engine': 'edge', 'name': 'Jenny', 'gender': 'female', 'style': 'Cheerful & Clear', 'best_for': 'Education, tutorials'},
        'sara': {'engine': 'edge', 'name': 'Sara', 'gender': 'female', 'style': 'Young & Energetic', 'best_for': 'Adventure, action'},
        'nancy': {'engine': 'edge', 'name': 'Nancy', 'gender': 'female', 'style': 'Professional', 'best_for': 'Business, formal'},
    }
    
    return jsonify({
        'voices': voices,
        'engine': 'edge_tts',
        'total': len(voices),
        'cost': 'FREE',
        'unlimited': True
    }), 200


@app.route('/api/generate-video', methods=['POST', 'OPTIONS'])
def generate_video():
    if request.method == 'OPTIONS':
        return '', 204
    
    data = request.json
    
    # Validate required fields
    if not data.get('topic'):
        return jsonify({'error': 'Topic is required'}), 400
    
    global progress_state
    progress_state = {
        'status': 'starting',
        'progress': 0,
        'video_path': None,
        'error': None,
        'voice_engine': None,
        'voice_id': None,
    }
    
    threading.Thread(target=generate_video_background, args=(data,)).start()
    return jsonify({'success': True, 'message': 'Generation started'}), 200


@app.route('/api/progress', methods=['GET', 'OPTIONS'])
def get_progress():
    if request.method == 'OPTIONS':
        return '', 204
    return jsonify(progress_state), 200


@app.route('/api/video/<path:filename>', methods=['GET', 'OPTIONS'])
def stream_video(filename):
    if request.method == 'OPTIONS':
        return '', 204
    
    try:
        video_path = f"output/videos/{filename}"
        return send_file(video_path, mimetype='video/mp4')
    except FileNotFoundError:
        return jsonify({'error': 'Video not found'}), 404


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TEMPLATE + RESEARCH ROUTES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@app.route('/api/analyze-script', methods=['POST', 'OPTIONS'])
def analyze_script_endpoint():
    """âœ… Analyze example script and extract template"""
    if request.method == 'OPTIONS':
        return '', 204
    
    try:
        data = request.json
        script_content = data.get('scriptContent', '')
        script_type = data.get('scriptType', 'story')
        
        if not script_content or len(script_content) < 100:
            return jsonify({'error': 'Script too short (min 100 chars)'}), 400
        
        print(f"\nğŸ“Š Analyzing script ({len(script_content)} chars)...")
        
        template = script_analyzer.analyze_script(script_content, script_type)
        
        print(f"âœ… Template extracted: {len(template)} fields")
        
        return jsonify(template), 200
    
    except Exception as e:
        print(f"âŒ Analysis failed: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/search-facts', methods=['POST', 'OPTIONS'])
def search_facts_endpoint():
    """âœ… Search facts for topic (for documentaries)"""
    if request.method == 'OPTIONS':
        return '', 204
    
    try:
        data = request.json
        topic = data.get('topic', '')
        story_type = data.get('story_type', 'historical_documentary')
        
        if not topic or len(topic) < 3:
            return jsonify({'error': 'Topic required (min 3 chars)'}), 400
        
        print(f"\nğŸ” Searching facts for: {topic}")
        
        result = fact_searcher.search_facts(topic, story_type)
        
        print(f"âœ… Found facts for: {topic}")
        
        return jsonify(result), 200
    
    except Exception as e:
        print(f"âŒ Search failed: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/generate-with-template', methods=['POST', 'OPTIONS'])
def generate_with_template_endpoint():
    """âœ… Generate script using template + optional research"""
    if request.method == 'OPTIONS':
        return '', 204
    
    global progress_state
    
    try:
        data = request.json
        
        if not data.get('topic'):
            return jsonify({'error': 'Topic required'}), 400
        
        topic = data.get('topic', '')
        story_type = data.get('story_type', 'scary_horror')
        template = data.get('template')
        research_data = data.get('research_data')
        duration = int(data.get('duration', 10))
        num_scenes = int(data.get('num_scenes', 10))
        voice_engine = data.get('voice_engine', 'inworld')
        voice_id = data.get('voice_id')
        voice_speed = float(data.get('voice_speed', 1.0))
        zoom_effect = data.get('zoom_effect', True)  # Default: True for better UX

        print(f"\nğŸ¬ Generating with template: {topic}")
        print(f"   Type: {story_type}")
        print(f"   Scenes: {num_scenes}")
        print(f"   Template: {'Yes' if template else 'No'}")
        print(f"   Research: {'Yes' if research_data else 'No'}")
        print(f"   Voice Engine: {voice_engine}")
        print(f"   Voice ID: {voice_id}")
        print(f"   Voice Speed: {voice_speed}x")
        print(f"   Zoom Effect: {'ENABLED' if zoom_effect else 'DISABLED'}")

        progress_state = {
            'status': 'starting',
            'progress': 0,
            'video_path': None,
            'error': None,
            'voice_engine': None,
            'voice_id': None,
        }
        
        thread = threading.Thread(
            target=generate_with_template_background,
            args=(topic, story_type, template, research_data, duration, num_scenes, voice_engine, voice_id, voice_speed, zoom_effect)
        )
        thread.start()

        return jsonify({
            'success': True,
            'message': 'Generation started',
            'used_template': template is not None,
            'used_research': research_data is not None,
            'voice_engine': voice_engine,
            'zoom_effect': zoom_effect
        }), 200
    
    except Exception as e:
        print(f"âŒ Generation failed: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/cache-stats', methods=['GET', 'OPTIONS'])
def cache_stats_endpoint():
    if request.method == 'OPTIONS':
        return '', 204
    
    try:
        stats = fact_searcher.get_cache_stats()
        return jsonify(stats), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/clear-cache', methods=['POST', 'OPTIONS'])
def clear_cache_endpoint():
    if request.method == 'OPTIONS':
        return '', 204
    
    try:
        fact_searcher.clear_cache()
        return jsonify({'success': True, 'message': 'Cache cleared'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == '__main__':
    print("\n" + "="*60)
    print("ğŸ”¥ PROFESSIONAL YOUTUBE VIDEO GENERATOR!")
    print("="*60)
    print("ğŸ“ URL: http://localhost:5001")
    print("âœ¨ Features: High Quality + Speed + FREE!")
    print("")
    print("ğŸ“ SCRIPT: Gemini AI (10/10 QUALITY!)")
    print("   - Enhanced prompts for better stories")
    print("   - Perfect timing calculation")
    print("   - ALL 5 senses, emotional depth")
    print("   - First-person narrative")
    print("   - Unique IMAGE descriptions")
    
    print("")
    print("ğŸ¤ VOICE: EDGE-TTS (Microsoft - FREE & UNLIMITED!)")
    print("   - 8 professional voices")
    print("   - FREE forever, no API key")
    print("   - Reliable, always works")
    print("   - $0 Forever!")
    
    print("")
    print("ğŸ¨ IMAGES: FLUX.1 Schnell (10/10 QUALITY, FREE)")
    print("   - Pollinations AI")
    print("   - Unique per scene")
    print("   - Cinematic variety")
    
    print("")
    print("ğŸ¬ VIDEO: FFmpeg + All Effects")
    print("   - 1080p HD quality")
    print("   - Zoom, captions, filters")
    print("   - 1-60 minute support")
    print("="*60)
    print("\nâœ… ENDPOINTS:")
    print("   GET  /health - Server status")
    print("   GET  /api/voices - List all voices")
    print("   POST /api/generate-video - Generate video (quick)")
    print("   POST /api/generate-with-template - Generate with template")
    print("   POST /api/analyze-script - Extract template")
    print("   POST /api/search-facts - Get research facts")
    print("   GET  /api/cache-stats - Cache statistics")
    print("   POST /api/clear-cache - Clear cache")
    print("="*60)
    print("\nğŸ† PROFESSIONAL YOUTUBE VIDEO GENERATOR READY!")
    print("ğŸ’° FREE - Puter TTS (voice) + Gemini (scripts) + FLUX (images)!")
    print("âš¡ Fast: 3-10 minutes for 10-60 minute videos")
    print("ğŸ¬ Quality: 10/10 - Professional YouTube content!")
    print("="*60 + "\n")
    
    app.run(host='0.0.0.0', port=5001, debug=True)