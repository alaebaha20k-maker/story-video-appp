{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¬ Professional AI Video Generator - GPU Server\n",
    "## Complete System with Coqui TTS + DreamShaper XL\n",
    "\n",
    "### âš ï¸ IMPORTANT INSTRUCTIONS:\n",
    "1. **Run Cell 1** â†’ Installs Python 3.10 environment\n",
    "2. **Wait for automatic restart** (30 seconds)\n",
    "3. **Run Cell 1 AGAIN** â†’ Installs all dependencies\n",
    "4. **Run Cell 2, 3, 4...** â†’ Everything will work!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“¦ CELL 1: INSTALL ALL DEPENDENCIES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# âš ï¸ RUN THIS CELL TWICE:\n",
    "#    First run: Installs Python 3.10, restarts runtime\n",
    "#    Second run (after restart): Installs all packages\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import sys\n",
    "\n",
    "print(f\"ğŸ“ Current Python: {sys.version}\\n\")\n",
    "\n",
    "if sys.version_info >= (3, 12):\n",
    "    print(\"âš ï¸  Python 3.12 detected - Coqui TTS needs Python 3.10!\")\n",
    "    print(\"ğŸ”„ Installing Python 3.10 environment...\\n\")\n",
    "    \n",
    "    # Install condacolab\n",
    "    !pip install -q condacolab\n",
    "    import condacolab\n",
    "    condacolab.install()\n",
    "    \n",
    "    print(\"\\nâœ… Python 3.10 environment installed!\")\n",
    "    print(\"âš ï¸  Runtime will restart automatically...\")\n",
    "    print(\"âš ï¸  AFTER RESTART: Run this cell again to install packages!\")\n",
    "    \n",
    "else:\n",
    "    print(f\"âœ… Python {sys.version_info.major}.{sys.version_info.minor} - Compatible!\\n\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ“¦ INSTALLING ALL DEPENDENCIES\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # FFmpeg\n",
    "    print(\"ğŸ¬ Installing FFmpeg...\")\n",
    "    !apt-get update -qq > /dev/null 2>&1\n",
    "    !apt-get install -y -qq ffmpeg > /dev/null 2>&1\n",
    "    !ffmpeg -version | head -n 1\n",
    "    print(\"   âœ… FFmpeg installed!\\n\")\n",
    "    \n",
    "    # Core packages\n",
    "    print(\"ğŸ“¦ Installing Flask and core packages...\")\n",
    "    !pip install -q --upgrade pip\n",
    "    !pip install -q flask flask-cors pyngrok requests\n",
    "    print(\"   âœ… Flask packages installed!\\n\")\n",
    "    \n",
    "    # PyTorch\n",
    "    print(\"ğŸ”¥ Installing PyTorch (GPU)...\")\n",
    "    !pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "    print(\"   âœ… PyTorch installed!\\n\")\n",
    "    \n",
    "    # Coqui TTS\n",
    "    print(\"ğŸ¤ Installing Coqui TTS...\")\n",
    "    !pip install -q TTS soundfile numpy scipy\n",
    "    print(\"   âœ… Coqui TTS installed!\\n\")\n",
    "    \n",
    "    # DreamShaper XL\n",
    "    print(\"ğŸ¨ Installing DreamShaper XL...\")\n",
    "    !pip install -q diffusers transformers accelerate safetensors\n",
    "    print(\"   âœ… DreamShaper XL installed!\\n\")\n",
    "    \n",
    "    # Image tools\n",
    "    print(\"ğŸ“¸ Installing image tools...\")\n",
    "    !pip install -q pillow opencv-python-headless\n",
    "    print(\"   âœ… Image tools installed!\\n\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"âœ… ALL DEPENDENCIES INSTALLED SUCCESSFULLY!\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nğŸ‘‰ Now run Cell 2 to setup GPU and imports!\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ”§ CELL 2: SETUP GPU & IMPORTS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "import json\n",
    "import subprocess\n",
    "import base64\n",
    "import time\n",
    "import io\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from flask_cors import CORS\n",
    "from pyngrok import ngrok\n",
    "from threading import Thread\n",
    "\n",
    "# GPU Detection\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ” GPU DETECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"âœ… GPU ENABLED: {gpu_name}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {gpu_memory:.1f} GB\")\n",
    "    print(f\"ğŸ”¥ CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print(\"âš ï¸  WARNING: GPU NOT DETECTED\")\n",
    "\n",
    "print(f\"\\nğŸš€ Device: {device}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('/content/outputs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"\\nğŸ“ Output directory: {output_dir}\")\n",
    "print(\"\\nâœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¨ CELL 3: LOAD IMAGE GENERATION MODEL (DreamShaper XL)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from diffusers import StableDiffusionXLPipeline\n",
    "\n",
    "# Global model variable\n",
    "img_pipeline = None\n",
    "\n",
    "# Style definitions for all 12 styles\n",
    "STYLE_DEFINITIONS = {\n",
    "    \"cinematic\": {\n",
    "        \"positive\": \"cinematic film still, movie quality, professional cinematography, depth of field, bokeh, film grain, dramatic lighting\",\n",
    "        \"negative\": \"amateur, low quality, blurry, cartoon, anime\"\n",
    "    },\n",
    "    \"documentary\": {\n",
    "        \"positive\": \"documentary photography, National Geographic style, photojournalism, natural lighting, authentic, real life\",\n",
    "        \"negative\": \"staged, fake, cartoon, anime, low quality\"\n",
    "    },\n",
    "    \"anime\": {\n",
    "        \"positive\": \"anime style, manga illustration, cel shaded, vibrant colors, Japanese animation, studio ghibli quality\",\n",
    "        \"negative\": \"photorealistic, 3D render, western cartoon, low quality\"\n",
    "    },\n",
    "    \"horror\": {\n",
    "        \"positive\": \"horror atmosphere, dark and creepy, ominous lighting, terrifying, nightmare fuel, psychological horror, eerie\",\n",
    "        \"negative\": \"bright, cheerful, colorful, cute, low quality\"\n",
    "    },\n",
    "    \"comic\": {\n",
    "        \"positive\": \"comic book art, graphic novel style, bold lines, dynamic composition, pop art colors, marvel comics style\",\n",
    "        \"negative\": \"photorealistic, blurry, low quality, amateur\"\n",
    "    },\n",
    "    \"historical\": {\n",
    "        \"positive\": \"historical photograph, vintage photo, sepia tone, aged photograph, 1920s style, grainy, archival quality\",\n",
    "        \"negative\": \"modern, digital, colorful, cartoon, low quality\"\n",
    "    },\n",
    "    \"scifi\": {\n",
    "        \"positive\": \"sci-fi concept art, cyberpunk, neon lights, futuristic technology, blade runner style, advanced technology\",\n",
    "        \"negative\": \"historical, vintage, low quality, blurry\"\n",
    "    },\n",
    "    \"noir\": {\n",
    "        \"positive\": \"film noir, high contrast black and white, dramatic shadows, 1940s detective aesthetic, cinematic\",\n",
    "        \"negative\": \"colorful, bright, cartoon, low quality\"\n",
    "    },\n",
    "    \"fantasy\": {\n",
    "        \"positive\": \"epic fantasy art, magical atmosphere, dungeons and dragons style, concept art, detailed, enchanted\",\n",
    "        \"negative\": \"modern, realistic, photograph, low quality\"\n",
    "    },\n",
    "    \"3d\": {\n",
    "        \"positive\": \"3D render, Pixar style, CGI graphics, Blender render, octane render, photorealistic 3D\",\n",
    "        \"negative\": \"2D, flat, painting, sketch, low quality\"\n",
    "    },\n",
    "    \"sketch\": {\n",
    "        \"positive\": \"pencil sketch, hand-drawn, charcoal drawing, line art, traditional art, artistic sketch\",\n",
    "        \"negative\": \"photorealistic, 3D render, colorful, low quality\"\n",
    "    },\n",
    "    \"watercolor\": {\n",
    "        \"positive\": \"watercolor painting, soft edges, flowing colors, artistic, traditional painting, hand-painted\",\n",
    "        \"negative\": \"photorealistic, 3D, digital art, low quality\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def load_image_model():\n",
    "    \"\"\"Load DreamShaper XL model\"\"\"\n",
    "    global img_pipeline\n",
    "    \n",
    "    if img_pipeline is None:\n",
    "        print(\"ğŸ¨ Loading DreamShaper XL (Supports ALL 12 styles!)...\")\n",
    "        \n",
    "        img_pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
    "            \"Lykon/dreamshaper-xl-1-0\",\n",
    "            torch_dtype=torch.float16,\n",
    "            variant=\"fp16\",\n",
    "            use_safetensors=True\n",
    "        ).to(device)\n",
    "        \n",
    "        img_pipeline.enable_xformers_memory_efficient_attention()\n",
    "        \n",
    "        print(\"   âœ… DreamShaper XL loaded!\")\n",
    "        print(\"   ğŸ¯ Supports: Realistic, Anime, Horror, Fantasy, Sci-Fi, etc.\")\n",
    "        print(\"   ğŸ“ Resolution: 1536x864 (16:9 ratio)\")\n",
    "    \n",
    "    return img_pipeline\n",
    "\n",
    "def generate_image(prompt, style=\"cinematic\"):\n",
    "    \"\"\"Generate image with specific style\"\"\"\n",
    "    \n",
    "    pipeline = load_image_model()\n",
    "    \n",
    "    # Get style keywords\n",
    "    style_def = STYLE_DEFINITIONS.get(style.lower(), STYLE_DEFINITIONS[\"cinematic\"])\n",
    "    \n",
    "    # Build full prompt\n",
    "    full_prompt = f\"{prompt}, {style_def['positive']}, highly detailed, professional quality, 8k\"\n",
    "    \n",
    "    # Generate\n",
    "    image = pipeline(\n",
    "        prompt=full_prompt,\n",
    "        negative_prompt=style_def['negative'],\n",
    "        num_inference_steps=25,\n",
    "        guidance_scale=7.5,\n",
    "        height=864,\n",
    "        width=1536\n",
    "    ).images[0]\n",
    "    \n",
    "    return image\n",
    "\n",
    "print(\"âœ… Image generation functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¤ CELL 4: VOICE MAPPING (Coqui TTS - VCTK Speakers)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "VOICE_MAPPING = {\n",
    "    # Male voices\n",
    "    'guy': 'p226',\n",
    "    'adam': 'p226',\n",
    "    'brian': 'p227',\n",
    "    'andrew': 'p243',\n",
    "    'michael': 'p232',\n",
    "    'george': 'p254',\n",
    "    'christopher': 'p259',\n",
    "    'davis_deep': 'p273',\n",
    "    \n",
    "    # Female voices\n",
    "    'aria': 'p229',\n",
    "    'sarah': 'p231',\n",
    "    'nicole': 'p233',\n",
    "    'jenny': 'p228',\n",
    "    'emma': 'p230',\n",
    "    'emma_british': 'p236',\n",
    "    'isabella': 'p244',\n",
    "    'sara': 'p231',\n",
    "    \n",
    "    # Defaults\n",
    "    'default_male': 'p226',\n",
    "    'default_female': 'p229',\n",
    "}\n",
    "\n",
    "def get_coqui_speaker(voice_id):\n",
    "    \"\"\"Get Coqui VCTK speaker ID from frontend voice ID\"\"\"\n",
    "    speaker = VOICE_MAPPING.get(voice_id, 'p226')\n",
    "    return speaker\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ¤ VOICE MAPPING CONFIGURED (COQUI TTS - VCTK SPEAKERS)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ… Total voices: {len(VOICE_MAPPING)}\")\n",
    "print(\"\\nğŸ“‹ Voice Categories:\")\n",
    "print(\"   â€¢ Male voices: guy, adam, brian, andrew, michael, george, christopher, davis_deep\")\n",
    "print(\"   â€¢ Female voices: aria, sarah, nicole, jenny, emma, emma_british, isabella, sara\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¤ CELL 5: VOICE GENERATION (Coqui TTS)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "from TTS.api import TTS\n",
    "import soundfile as sf\n",
    "\n",
    "# Global TTS model\n",
    "tts_model = None\n",
    "\n",
    "def load_tts_model():\n",
    "    \"\"\"Load Coqui TTS model\"\"\"\n",
    "    global tts_model\n",
    "    \n",
    "    if tts_model is None:\n",
    "        print(\"ğŸ¤ Loading Coqui TTS (PyTorch GPU)...\")\n",
    "        tts_model = TTS(\"tts_models/en/vctk/vits\").to(device)\n",
    "        print(\"   âœ… Coqui TTS loaded!\")\n",
    "    \n",
    "    return tts_model\n",
    "\n",
    "def generate_voice(text, voice_id, output_path):\n",
    "    \"\"\"Generate voice audio with Coqui TTS\"\"\"\n",
    "    \n",
    "    # Get speaker ID\n",
    "    speaker = get_coqui_speaker(voice_id)\n",
    "    \n",
    "    # Load model\n",
    "    tts = load_tts_model()\n",
    "    \n",
    "    # Generate audio\n",
    "    tts.tts_to_file(\n",
    "        text=text,\n",
    "        speaker=speaker,\n",
    "        file_path=output_path\n",
    "    )\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "print(\"âœ… Voice generation functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸš€ CELL 6: FLASK SERVER & ROUTES\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({\"status\": \"ok\", \"gpu\": torch.cuda.is_available()})\n",
    "\n",
    "@app.route('/generate_audio', methods=['POST'])\n",
    "def generate_audio():\n",
    "    try:\n",
    "        data = request.get_json(force=True)\n",
    "        text = data.get('text', '')\n",
    "        voice = data.get('voice', 'aria')\n",
    "        import uuid\n",
    "        audio_path = output_dir / f\"audio_{uuid.uuid4()}.wav\"\n",
    "        generate_voice(text, voice, str(audio_path))\n",
    "        return send_file(str(audio_path), mimetype='audio/wav')\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/generate_image', methods=['POST'])\n",
    "def generate_single_image():\n",
    "    try:\n",
    "        data = request.get_json(force=True)\n",
    "        prompt = data.get('prompt', '')\n",
    "        style = data.get('style', 'cinematic')\n",
    "        image = generate_image(prompt, style)\n",
    "        import uuid\n",
    "        image_path = output_dir / f\"image_{uuid.uuid4()}.png\"\n",
    "        image.save(image_path)\n",
    "        return send_file(str(image_path), mimetype='image/png')\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/generate_images_batch', methods=['POST'])\n",
    "def generate_images_batch():\n",
    "    try:\n",
    "        data = request.get_json(force=True)\n",
    "        scenes = data.get('scenes', [])\n",
    "        style = data.get('style', 'cinematic')\n",
    "        results = []\n",
    "        for i, scene in enumerate(scenes):\n",
    "            prompt = scene.get('description', '')\n",
    "            image = generate_image(prompt, style)\n",
    "            buffer = io.BytesIO()\n",
    "            image.save(buffer, format='PNG')\n",
    "            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')\n",
    "            results.append({'success': True, 'image_data': image_base64, 'scene_index': i})\n",
    "        return jsonify({'results': results})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/compile_video', methods=['POST'])\n",
    "def compile_video():\n",
    "    try:\n",
    "        data = request.get_json(force=True)\n",
    "        return jsonify({\"success\": True})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/generate_complete_video', methods=['POST'])\n",
    "def generate_complete_video():\n",
    "    \"\"\"Generate complete video with images, voice, and effects\"\"\"\n",
    "    try:\n",
    "        data = request.get_json(force=True)\n",
    "        \n",
    "        # Extract data\n",
    "        script = data.get('script', '')\n",
    "        image_prompts = data.get('image_prompts', [])\n",
    "        voice = data.get('voice', 'aria')\n",
    "        style = data.get('style', 'cinematic')\n",
    "        \n",
    "        print(f\"ğŸ“ Received request:\")\n",
    "        print(f\"   Script: {len(script)} chars\")\n",
    "        print(f\"   Images: {len(image_prompts)} prompts\")\n",
    "        print(f\"   Voice: {voice}\")\n",
    "        print(f\"   Style: {style}\")\n",
    "        \n",
    "        # Create work directory\n",
    "        import uuid\n",
    "        job_id = str(uuid.uuid4())\n",
    "        work_dir = output_dir / job_id\n",
    "        work_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Generate images\n",
    "        print(f\"\\nğŸ¨ Generating {len(image_prompts)} images...\")\n",
    "        for i, prompt in enumerate(image_prompts):\n",
    "            print(f\"   [{i+1}/{len(image_prompts)}] {prompt[:50]}...\")\n",
    "            image = generate_image(prompt, style)\n",
    "            image.save(work_dir / f\"image_{i:04d}.png\")\n",
    "        \n",
    "        # Generate voice\n",
    "        print(f\"\\nğŸ¤ Generating voice...\")\n",
    "        audio_path = work_dir / \"voice.wav\"\n",
    "        generate_voice(script, voice, str(audio_path))\n",
    "        \n",
    "        # Compile video with FFmpeg\n",
    "        print(f\"\\nğŸ¬ Compiling video...\")\n",
    "        output_path = work_dir / \"final_video.mp4\"\n",
    "        \n",
    "        ffmpeg_cmd = [\n",
    "            'ffmpeg', '-y',\n",
    "            '-hwaccel', 'cuda',\n",
    "            '-framerate', '30',\n",
    "            '-pattern_type', 'glob',\n",
    "            '-i', str(work_dir / 'image_*.png'),\n",
    "            '-i', str(audio_path),\n",
    "            '-c:v', 'h264_nvenc',\n",
    "            '-preset', 'fast',\n",
    "            '-b:v', '10M',\n",
    "            '-c:a', 'aac',\n",
    "            '-b:a', '192k',\n",
    "            '-pix_fmt', 'yuv420p',\n",
    "            '-s', '1920x1080',\n",
    "            str(output_path)\n",
    "        ]\n",
    "        \n",
    "        subprocess.run(ffmpeg_cmd, check=True)\n",
    "        \n",
    "        print(f\"\\nâœ… Video generated: {output_path}\")\n",
    "        \n",
    "        return jsonify({\n",
    "            \"success\": True,\n",
    "            \"job_id\": job_id,\n",
    "            \"video_path\": str(output_path)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "@app.route('/download/<job_id>', methods=['GET'])\n",
    "def download_video(job_id):\n",
    "    \"\"\"Download generated video\"\"\"\n",
    "    video_path = output_dir / job_id / \"final_video.mp4\"\n",
    "    if video_path.exists():\n",
    "        return send_file(str(video_path), mimetype='video/mp4')\n",
    "    return jsonify({\"error\": \"Video not found\"}), 404\n",
    "\n",
    "print(\"âœ… Flask server configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸŒ CELL 7: START SERVER WITH NGROK\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Configure ngrok token\n",
    "NGROK_AUTH_TOKEN = \"2gacBVJPhjmZXiON9TYHmhI8TkN_39DL8HL8ug3xR7i6QWw9h\"\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "\n",
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(5001)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸŒ NGROK PUBLIC URL:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   {public_url}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nğŸ”§ UPDATE YOUR BACKEND:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"   File: config/__init__.py\")\n",
    "print(f\"   Set: COLAB_SERVER_URL = '{public_url}'\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ALL FEATURES READY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nğŸŒŸ Server starting on port 5001...\")\n",
    "print(\"Press Ctrl+C to stop.\\n\")\n",
    "\n",
    "# Start Flask server\n",
    "try:\n",
    "    app.run(host='0.0.0.0', port=5001, debug=False, use_reloader=False)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nğŸ›‘ Server stopped!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
