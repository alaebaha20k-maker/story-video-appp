{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Complete GPU Server - Image + Voice API (FIXED)\n",
    "## âœ… Fixes ALL Issues: Kokoro Import, SDXL Files, diffusers\n",
    "\n",
    "### Critical Fixes Applied:\n",
    "1. âœ… **Kokoro TTS**: Proper installation & KPipeline usage\n",
    "2. âœ… **SDXL Images**: Absolute paths, file verification, proper saving\n",
    "3. âœ… **diffusers**: Correct imports (DiffusionPipeline)\n",
    "\n",
    "### Instructions:\n",
    "1. **Runtime â†’ Change runtime type â†’ GPU (T4)**\n",
    "2. Run cells 1-6 in order\n",
    "3. Add your ngrok token in cell 7\n",
    "4. Run cell 7 and 8 to start server\n",
    "5. Copy the ngrok URL\n",
    "6. Update your local `.env` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ STEP 1: Install Dependencies (WITH PROPER VERSIONS)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“¦ Installing Dependencies...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Install PyTorch with CUDA support\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install diffusers with compatible version\n",
    "!pip install -q \"diffusers>=0.24.0\" transformers accelerate safetensors\n",
    "\n",
    "# Install Flask and ngrok\n",
    "!pip install -q flask flask-cors pyngrok\n",
    "\n",
    "# Install image/audio libraries\n",
    "!pip install -q pillow numpy soundfile scipy\n",
    "\n",
    "# âœ… CRITICAL: Install Kokoro TTS BEFORE any imports\n",
    "print(\"\\nğŸ¤ Installing Kokoro TTS...\")\n",
    "!pip install -q \"kokoro-onnx>=0.1.0\"\n",
    "\n",
    "print(\"\\nâœ… All dependencies installed!\")\n",
    "print(\"   âš ï¸  DO NOT restart runtime before running next cells!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ STEP 2: Import Libraries and Check GPU\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”§ Importing libraries and checking environment...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "import torch\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "from PIL import Image\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Check GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ® Device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"   âš ï¸  WARNING: No GPU! Change Runtime â†’ Change runtime type â†’ GPU\")\n",
    "\n",
    "# Create output directories with absolute paths\n",
    "IMAGES_DIR = \"/content/generated_images\"\n",
    "AUDIO_DIR = \"/content/generated_audio\"\n",
    "os.makedirs(IMAGES_DIR, exist_ok=True)\n",
    "os.makedirs(AUDIO_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"\\nğŸ“ Working directories:\")\n",
    "print(f\"   Images: {IMAGES_DIR}\")\n",
    "print(f\"   Audio: {AUDIO_DIR}\")\n",
    "print(\"\\nâœ… Environment ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¨ STEP 3: Load SDXL-Turbo (FIXED IMPORT)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¨ Loading SDXL-Turbo for image generation...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "# Load SDXL-Turbo with correct pipeline class\n",
    "print(\"ğŸ“¥ Downloading model (first time only, ~7GB)...\")\n",
    "sdxl_pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/sdxl-turbo\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    variant=\"fp16\" if device == \"cuda\" else None,\n",
    "    use_safetensors=True\n",
    ")\n",
    "\n",
    "sdxl_pipe = sdxl_pipe.to(device)\n",
    "\n",
    "# Enable optimizations for T4 GPU\n",
    "if device == \"cuda\":\n",
    "    try:\n",
    "        sdxl_pipe.enable_xformers_memory_efficient_attention()\n",
    "        print(\"   âœ… xFormers memory optimization enabled\")\n",
    "    except:\n",
    "        print(\"   â„¹ï¸  xFormers not available, using default attention\")\n",
    "    \n",
    "    # Enable VAE slicing for lower VRAM\n",
    "    sdxl_pipe.enable_vae_slicing()\n",
    "    print(\"   âœ… VAE slicing enabled (lower VRAM usage)\")\n",
    "\n",
    "print(\"\\nâœ… SDXL-Turbo loaded successfully!\")\n",
    "print(f\"   Model: stabilityai/sdxl-turbo\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Resolution: 1024x1024\")\n",
    "print(f\"   Speed: 1-4 inference steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤ STEP 4: Setup Kokoro TTS (FIXED - KPipeline)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¤ Setting up Kokoro TTS...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# âœ… CRITICAL FIX: Import kokoro AFTER installation in Step 1\n",
    "try:\n",
    "    from kokoro import KPipeline\n",
    "    import soundfile as sf\n",
    "    KOKORO_AVAILABLE = True\n",
    "    print(\"âœ… Kokoro module imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ ERROR: Cannot import Kokoro: {e}\")\n",
    "    print(\"   Please restart runtime and run cells again from the beginning.\")\n",
    "    KOKORO_AVAILABLE = False\n",
    "\n",
    "# Global TTS pipeline\n",
    "tts_pipeline = None\n",
    "\n",
    "def load_tts_model():\n",
    "    \"\"\"Load Kokoro TTS pipeline (lazy loading)\"\"\"\n",
    "    global tts_pipeline\n",
    "    \n",
    "    if not KOKORO_AVAILABLE:\n",
    "        raise RuntimeError(\"Kokoro is not available. Restart runtime and re-run all cells.\")\n",
    "    \n",
    "    if tts_pipeline is None:\n",
    "        print(\"   ğŸ¤ Loading Kokoro TTS pipeline...\")\n",
    "        # Use 'a' for American English (supports most voices)\n",
    "        tts_pipeline = KPipeline(lang_code='a')\n",
    "        print(\"   âœ… Kokoro pipeline loaded!\")\n",
    "    \n",
    "    return tts_pipeline\n",
    "\n",
    "# Voice mapping: user-friendly â†’ Kokoro voice IDs\n",
    "VOICE_MAP = {\n",
    "    'aria': 'af_sarah',\n",
    "    'guy': 'am_adam',\n",
    "    'jenny': 'af_nicole',\n",
    "    'christopher': 'am_michael',\n",
    "    'sara': 'af_bella',\n",
    "    'sarah': 'af_sarah',\n",
    "    'roger': 'am_adam',\n",
    "    'nancy': 'af_jessica',\n",
    "    'andrew': 'am_adam',\n",
    "}\n",
    "\n",
    "if KOKORO_AVAILABLE:\n",
    "    print(f\"\\nâœ… Kokoro TTS ready!\")\n",
    "    print(f\"   Available voices: {len(VOICE_MAP)}\")\n",
    "    print(f\"   Sample rate: 24kHz\")\n",
    "    print(f\"   Quality: Professional studio\")\n",
    "else:\n",
    "    print(\"\\nâŒ Kokoro TTS NOT available!\")\n",
    "    print(\"   Audio generation will fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”Œ STEP 5: Create Flask API Server (FIXED)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”Œ Creating Flask API server...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# IMAGE GENERATION - FIXED FILE SAVING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@app.route('/generate_image', methods=['POST'])\n",
    "def generate_image():\n",
    "    \"\"\"Generate image with SDXL-Turbo (FIXED)\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        prompt = data.get('prompt', '')\n",
    "        scene_id = data.get('scene_id', 0)\n",
    "        \n",
    "        if not prompt:\n",
    "            return jsonify({'error': 'Prompt is required'}), 400\n",
    "        \n",
    "        print(f\"\\nğŸ¨ Generating image for scene {scene_id}...\")\n",
    "        print(f\"   Prompt: {prompt[:80]}...\")\n",
    "        \n",
    "        # Generate with SDXL-Turbo\n",
    "        image = sdxl_pipe(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=2,\n",
    "            guidance_scale=0.0,\n",
    "            height=1024,\n",
    "            width=1024\n",
    "        ).images[0]\n",
    "        \n",
    "        # âœ… FIX: Save to absolute path and verify\n",
    "        import time\n",
    "        timestamp = int(time.time() * 1000)\n",
    "        filename = f\"scene_{scene_id:03d}_{timestamp}.png\"\n",
    "        save_path = os.path.join(IMAGES_DIR, filename)\n",
    "        \n",
    "        print(f\"   ğŸ’¾ Saving to: {save_path}\")\n",
    "        image.save(save_path, format='PNG')\n",
    "        \n",
    "        # âœ… VERIFY file exists\n",
    "        if not os.path.exists(save_path):\n",
    "            raise RuntimeError(f\"Failed to save image! Path: {save_path}\")\n",
    "        \n",
    "        file_size = os.path.getsize(save_path) / 1024  # KB\n",
    "        print(f\"   âœ… Saved successfully! Size: {file_size:.1f} KB\")\n",
    "        \n",
    "        # Convert to base64 for transmission\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        image.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'image': img_base64,\n",
    "            'format': 'png',\n",
    "            'filename': filename,\n",
    "            'path': save_path,\n",
    "            'size_kb': file_size\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# VOICE GENERATION - FIXED KOKORO IMPORT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@app.route('/generate_audio', methods=['POST'])\n",
    "def generate_audio():\n",
    "    \"\"\"Generate audio with Kokoro TTS (FIXED)\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        text = data.get('text', '')\n",
    "        voice = data.get('voice', 'aria')\n",
    "        speed = float(data.get('speed', 1.0))\n",
    "        \n",
    "        if not text:\n",
    "            return jsonify({'error': 'Text is required'}), 400\n",
    "        \n",
    "        if not KOKORO_AVAILABLE:\n",
    "            return jsonify({'error': 'Kokoro TTS is not available. Restart runtime.'}), 500\n",
    "        \n",
    "        # Map voice\n",
    "        kokoro_voice = VOICE_MAP.get(voice.lower(), 'af_sarah')\n",
    "        \n",
    "        print(f\"\\nğŸ¤ Generating audio: {voice} â†’ {kokoro_voice}\")\n",
    "        print(f\"   Text: {text[:80]}...\")\n",
    "        print(f\"   Speed: {speed}x\")\n",
    "        \n",
    "        # âœ… Load pipeline\n",
    "        pipeline = load_tts_model()\n",
    "        \n",
    "        # âœ… Generate audio chunks\n",
    "        if len(text) > 1000:\n",
    "            print(f\"   ğŸ“ Splitting into chunks (text is long)...\")\n",
    "            chunks = split_text_smart(text, max_chars=800)\n",
    "            audio_segments = []\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                print(f\"   Processing chunk {i+1}/{len(chunks)}...\")\n",
    "                results = list(pipeline(chunk, voice=kokoro_voice, speed=speed))\n",
    "                \n",
    "                if not results or not hasattr(results[0], 'audio'):\n",
    "                    raise RuntimeError(f\"Chunk {i+1} failed: no audio returned\")\n",
    "                \n",
    "                audio_tensor = results[0].audio.cpu().numpy()\n",
    "                audio_segments.append(audio_tensor)\n",
    "            \n",
    "            # Concatenate\n",
    "            audio = np.concatenate(audio_segments)\n",
    "        else:\n",
    "            # Short text - generate directly\n",
    "            results = list(pipeline(text, voice=kokoro_voice, speed=speed))\n",
    "            \n",
    "            if not results or not hasattr(results[0], 'audio'):\n",
    "                raise RuntimeError(\"Kokoro returned no audio\")\n",
    "            \n",
    "            audio = results[0].audio.cpu().numpy()\n",
    "        \n",
    "        # âœ… Save audio to file\n",
    "        import time\n",
    "        timestamp = int(time.time() * 1000)\n",
    "        filename = f\"audio_{timestamp}.wav\"\n",
    "        save_path = os.path.join(AUDIO_DIR, filename)\n",
    "        \n",
    "        sample_rate = 24000  # Kokoro sample rate\n",
    "        sf.write(save_path, audio, sample_rate)\n",
    "        \n",
    "        # âœ… VERIFY\n",
    "        if not os.path.exists(save_path):\n",
    "            raise RuntimeError(f\"Failed to save audio! Path: {save_path}\")\n",
    "        \n",
    "        # Convert to base64\n",
    "        audio_byte_arr = io.BytesIO()\n",
    "        sf.write(audio_byte_arr, audio, sample_rate, format='WAV')\n",
    "        audio_byte_arr.seek(0)\n",
    "        audio_base64 = base64.b64encode(audio_byte_arr.getvalue()).decode('utf-8')\n",
    "        \n",
    "        duration = len(audio) / sample_rate\n",
    "        print(f\"   âœ… Audio generated! Duration: {duration:.1f}s\")\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'audio': audio_base64,\n",
    "            'format': 'wav',\n",
    "            'duration': duration,\n",
    "            'sample_rate': sample_rate,\n",
    "            'filename': filename,\n",
    "            'path': save_path\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# HEALTH CHECK\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'ok',\n",
    "        'device': device,\n",
    "        'gpu': torch.cuda.get_device_name(0) if device == 'cuda' else 'none',\n",
    "        'services': {\n",
    "            'sdxl_turbo': 'ready',\n",
    "            'kokoro_tts': 'ready' if KOKORO_AVAILABLE else 'unavailable'\n",
    "        },\n",
    "        'paths': {\n",
    "            'images': IMAGES_DIR,\n",
    "            'audio': AUDIO_DIR\n",
    "        }\n",
    "    })\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# HELPER\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def split_text_smart(text, max_chars=800):\n",
    "    \"\"\"Split text at sentence boundaries\"\"\"\n",
    "    sentences = text.replace('!', '.').replace('?', '.').split('.')\n",
    "    sentences = [s.strip() + '.' for s in sentences if s.strip()]\n",
    "    \n",
    "    chunks = []\n",
    "    current = \"\"\n",
    "    \n",
    "    for sent in sentences:\n",
    "        if len(current) + len(sent) <= max_chars:\n",
    "            current += \" \" + sent\n",
    "        else:\n",
    "            if current:\n",
    "                chunks.append(current.strip())\n",
    "            current = sent\n",
    "    \n",
    "    if current:\n",
    "        chunks.append(current.strip())\n",
    "    \n",
    "    return chunks if chunks else [text]\n",
    "\n",
    "print(\"\\nâœ… Flask API server created!\")\n",
    "print(\"   Endpoints:\")\n",
    "print(\"   - POST /generate_image\")\n",
    "print(\"   - POST /generate_audio\")\n",
    "print(\"   - GET  /health\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸŒ STEP 6: Setup ngrok\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸŒ ngrok Setup\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "print(\"ğŸ“ Instructions:\")\n",
    "print(\"   1. Get free ngrok token: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "print(\"   2. Edit the NGROK_AUTH_TOKEN variable below\")\n",
    "print(\"   3. Run this cell\")\n",
    "print(\"   4. Then run STEP 7 to start the server\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”‘ STEP 7: Set ngrok Token (EDIT THIS!)\n",
    "\n",
    "# â¬‡ï¸ REPLACE WITH YOUR ACTUAL TOKEN â¬‡ï¸\n",
    "NGROK_AUTH_TOKEN = \"YOUR_NGROK_TOKEN_HERE\"\n",
    "# â¬†ï¸ REPLACE WITH YOUR ACTUAL TOKEN â¬†ï¸\n",
    "\n",
    "if NGROK_AUTH_TOKEN == \"YOUR_NGROK_TOKEN_HERE\":\n",
    "    print(\"âŒ ERROR: You must set your ngrok token!\")\n",
    "    print(\"\\nğŸ“ Steps:\")\n",
    "    print(\"   1. Get token: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "    print(\"   2. Edit NGROK_AUTH_TOKEN in the cell above\")\n",
    "    print(\"   3. Run this cell again\")\n",
    "else:\n",
    "    from pyngrok import ngrok\n",
    "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "    print(\"âœ… ngrok token configured!\")\n",
    "    print(\"\\nâ¡ï¸  Now run STEP 8 to start the server.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ STEP 8: START SERVER!\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ STARTING GPU SERVER\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(5000, bind_tls=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… GPU SERVER IS RUNNING!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸŒ PUBLIC URL:\")\n",
    "print(f\"   {public_url}\")\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“‹ SETUP YOUR LOCAL APP:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n1. Create/edit .env file in your project:\")\n",
    "print(f\"\\n   SDXL_API_URL={public_url}/generate_image\")\n",
    "print(f\"   KOKORO_API_URL={public_url}/generate_audio\")\n",
    "print(f\"\\n2. Restart your local app\")\n",
    "print(f\"\\n3. Generate videos!\")\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"ğŸ§ª TEST ENDPOINTS:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n   curl {public_url}/health\")\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"âš ï¸  Keep this notebook running!\")\n",
    "print(\"   Closing it will stop the server.\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Start Flask (blocking)\n",
    "app.run(port=5000, debug=False, use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
