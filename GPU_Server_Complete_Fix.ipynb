{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Complete GPU Server - Image + Voice API\n",
    "## âœ… Fixes ALL Issues for SDXL-Turbo + Kokoro TTS\n",
    "\n",
    "### What This Notebook Does:\n",
    "1. âœ… Sets up SDXL-Turbo for ultra-fast image generation\n",
    "2. âœ… Sets up Kokoro TTS with proper model initialization\n",
    "3. âœ… Creates Flask API endpoints for both services\n",
    "4. âœ… Exposes via ngrok for remote access\n",
    "\n",
    "### Instructions:\n",
    "1. Run all cells in order\n",
    "2. Copy the ngrok URL that appears\n",
    "3. Paste it into your local app's `.env` file\n",
    "4. Generate videos with GPU-powered image and voice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“¦ STEP 1: Install All Dependencies\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ“¦ Installing Dependencies...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q diffusers transformers accelerate safetensors\n",
    "!pip install -q flask flask-cors pyngrok\n",
    "!pip install -q pillow numpy soundfile scipy\n",
    "\n",
    "# Install Kokoro TTS\n",
    "!pip install -q kokoro-onnx\n",
    "\n",
    "print(\"âœ… All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”§ STEP 2: Import Libraries and Setup\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”§ Setting up environment...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "import torch\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from flask_cors import CORS\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "import threading\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Check GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ® Device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"   âš ï¸  No GPU detected - will be slow!\")\n",
    "\n",
    "print(\"\\nâœ… Environment ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¨ STEP 3: Load SDXL-Turbo Model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¨ Loading SDXL-Turbo (Fast Image Generation)...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Load SDXL-Turbo pipeline\n",
    "sdxl_pipe = AutoPipelineForText2Image.from_pretrained(\n",
    "    \"stabilityai/sdxl-turbo\",\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    variant=\"fp16\" if device == \"cuda\" else None\n",
    ")\n",
    "\n",
    "sdxl_pipe = sdxl_pipe.to(device)\n",
    "\n",
    "# Enable memory optimizations\n",
    "if device == \"cuda\":\n",
    "    sdxl_pipe.enable_xformers_memory_efficient_attention()\n",
    "    print(\"   âœ… Memory optimizations enabled\")\n",
    "\n",
    "print(\"\\nâœ… SDXL-Turbo loaded and ready!\")\n",
    "print(f\"   Model: stabilityai/sdxl-turbo\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Speed: 1-4 steps (ultra-fast!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¤ STEP 4: Setup Kokoro TTS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ¤ Setting up Kokoro TTS (Professional Voice)...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "from kokoro import Kokoro\n",
    "\n",
    "# Download and cache Kokoro models\n",
    "print(\"ğŸ“¥ Downloading Kokoro models (first time only)...\")\n",
    "\n",
    "# Create Kokoro instance with automatic model download\n",
    "kokoro = None\n",
    "\n",
    "def get_kokoro_instance():\n",
    "    \"\"\"Lazy load Kokoro instance\"\"\"\n",
    "    global kokoro\n",
    "    if kokoro is None:\n",
    "        print(\"   Loading Kokoro TTS models...\")\n",
    "        # Initialize Kokoro with default models (will auto-download)\n",
    "        kokoro = Kokoro.from_pretrained()\n",
    "        print(\"   âœ… Kokoro loaded!\")\n",
    "    return kokoro\n",
    "\n",
    "# Voice mapping from user-friendly names to Kokoro voices\n",
    "VOICE_MAP = {\n",
    "    'aria': 'af_sarah',  # Professional female\n",
    "    'guy': 'am_adam',    # Professional male\n",
    "    'jenny': 'af_nicole', # Cheerful female\n",
    "    'christopher': 'am_michael', # Casual male\n",
    "    'sara': 'af_bella',  # Young female\n",
    "    'roger': 'am_adam',  # Authoritative male\n",
    "    'nancy': 'af_jessica', # Professional female\n",
    "    'andrew': 'am_adam', # Business male\n",
    "}\n",
    "\n",
    "print(\"\\nâœ… Kokoro TTS ready!\")\n",
    "print(f\"   Voices: {len(VOICE_MAP)} available\")\n",
    "print(f\"   Quality: Professional studio quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”Œ STEP 5: Create Flask API Server\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ”Œ Creating Flask API server...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# IMAGE GENERATION ENDPOINT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@app.route('/generate_image', methods=['POST'])\n",
    "def generate_image():\n",
    "    \"\"\"Generate image with SDXL-Turbo\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        prompt = data.get('prompt', '')\n",
    "        \n",
    "        if not prompt:\n",
    "            return jsonify({'error': 'Prompt is required'}), 400\n",
    "        \n",
    "        print(f\"\\nğŸ¨ Generating image...\")\n",
    "        print(f\"   Prompt: {prompt[:100]}...\")\n",
    "        \n",
    "        # Generate image with SDXL-Turbo (1-4 steps for speed!)\n",
    "        image = sdxl_pipe(\n",
    "            prompt=prompt,\n",
    "            num_inference_steps=2,  # Ultra-fast!\n",
    "            guidance_scale=0.0,     # Turbo doesn't need guidance\n",
    "            height=1024,\n",
    "            width=1024\n",
    "        ).images[0]\n",
    "        \n",
    "        # Convert to bytes\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        image.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr.seek(0)\n",
    "        \n",
    "        # Convert to base64\n",
    "        img_base64 = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        \n",
    "        print(f\"   âœ… Image generated successfully!\")\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'image': img_base64,\n",
    "            'format': 'png'\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {str(e)}\")\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# VOICE GENERATION ENDPOINT\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@app.route('/generate_audio', methods=['POST'])\n",
    "def generate_audio():\n",
    "    \"\"\"Generate audio with Kokoro TTS\"\"\"\n",
    "    try:\n",
    "        data = request.json\n",
    "        text = data.get('text', '')\n",
    "        voice = data.get('voice', 'aria')\n",
    "        speed = float(data.get('speed', 1.0))\n",
    "        \n",
    "        if not text:\n",
    "            return jsonify({'error': 'Text is required'}), 400\n",
    "        \n",
    "        # Map voice name to Kokoro voice\n",
    "        kokoro_voice = VOICE_MAP.get(voice.lower(), 'af_sarah')\n",
    "        \n",
    "        print(f\"\\nğŸ¤ Generating audio...\")\n",
    "        print(f\"   Voice: {voice} â†’ {kokoro_voice}\")\n",
    "        print(f\"   Speed: {speed}x\")\n",
    "        print(f\"   Text length: {len(text)} characters\")\n",
    "        \n",
    "        # Get Kokoro instance\n",
    "        k = get_kokoro_instance()\n",
    "        \n",
    "        # Generate audio\n",
    "        # Split long text into chunks for better processing\n",
    "        if len(text) > 1000:\n",
    "            print(f\"   ğŸ“ Splitting long text into chunks...\")\n",
    "            chunks = split_text_smart(text, max_chars=1000)\n",
    "            audio_chunks = []\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                print(f\"   Processing chunk {i+1}/{len(chunks)}...\")\n",
    "                audio_chunk = k.generate(chunk, voice=kokoro_voice, speed=speed)\n",
    "                audio_chunks.append(audio_chunk)\n",
    "            \n",
    "            # Concatenate all chunks\n",
    "            audio = np.concatenate(audio_chunks)\n",
    "        else:\n",
    "            audio = k.generate(text, voice=kokoro_voice, speed=speed)\n",
    "        \n",
    "        # Save to bytes\n",
    "        audio_byte_arr = io.BytesIO()\n",
    "        sf.write(audio_byte_arr, audio, k.sample_rate, format='WAV')\n",
    "        audio_byte_arr.seek(0)\n",
    "        \n",
    "        # Convert to base64\n",
    "        audio_base64 = base64.b64encode(audio_byte_arr.getvalue()).decode('utf-8')\n",
    "        \n",
    "        duration = len(audio) / k.sample_rate\n",
    "        print(f\"   âœ… Audio generated! Duration: {duration:.1f}s\")\n",
    "        \n",
    "        return jsonify({\n",
    "            'success': True,\n",
    "            'audio': audio_base64,\n",
    "            'format': 'wav',\n",
    "            'duration': duration,\n",
    "            'sample_rate': k.sample_rate\n",
    "        })\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# HEALTH CHECK\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return jsonify({\n",
    "        'status': 'ok',\n",
    "        'device': device,\n",
    "        'services': {\n",
    "            'sdxl_turbo': 'ready',\n",
    "            'kokoro_tts': 'ready'\n",
    "        }\n",
    "    })\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# HELPER FUNCTIONS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def split_text_smart(text, max_chars=1000):\n",
    "    \"\"\"Split text at sentence boundaries\"\"\"\n",
    "    sentences = text.replace('!', '.').replace('?', '.').split('.')\n",
    "    sentences = [s.strip() + '.' for s in sentences if s.strip()]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) <= max_chars:\n",
    "            current_chunk += \" \" + sentence\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks if chunks else [text]\n",
    "\n",
    "print(\"\\nâœ… Flask API server created!\")\n",
    "print(\"   Endpoints:\")\n",
    "print(\"   POST /generate_image - Generate images with SDXL-Turbo\")\n",
    "print(\"   POST /generate_audio - Generate audio with Kokoro TTS\")\n",
    "print(\"   GET  /health - Health check\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸŒ STEP 6: Setup ngrok Tunnel\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸŒ Setting up ngrok tunnel...\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Set your ngrok auth token here (get from: https://dashboard.ngrok.com/get-started/your-authtoken)\n",
    "NGROK_AUTH_TOKEN = \"YOUR_NGROK_TOKEN_HERE\"  # Replace with your token\n",
    "\n",
    "# If you don't have a token, get one free at: https://ngrok.com/\n",
    "if NGROK_AUTH_TOKEN == \"YOUR_NGROK_TOKEN_HERE\":\n",
    "    print(\"âš ï¸  Please set your ngrok auth token!\")\n",
    "    print(\"   1. Go to: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "    print(\"   2. Copy your token\")\n",
    "    print(\"   3. Replace NGROK_AUTH_TOKEN in the cell above\")\n",
    "    print(\"   4. Run this cell again\")\n",
    "else:\n",
    "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "    print(\"âœ… ngrok token set!\")\n",
    "\n",
    "print(\"\\nğŸ“ Note: If you don't have an ngrok token:\")\n",
    "print(\"   - Free tier: 1 concurrent tunnel, no custom domains\")\n",
    "print(\"   - Sign up at: https://ngrok.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš€ STEP 7: Start Server!\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸš€ STARTING GPU SERVER!\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(5000, bind_tls=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ… GPU SERVER IS RUNNING!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸŒ Your Public URL:\")\n",
    "print(f\"   {public_url}\")\n",
    "print(\"\\nğŸ“‹ Copy this URL and use it in your local app!\")\n",
    "print(\"\\nğŸ”§ Setup Instructions:\")\n",
    "print(\"   1. Copy the URL above\")\n",
    "print(\"   2. In your local project, create/update .env file:\")\n",
    "print(f\"      SDXL_TURBO_API_URL={public_url}/generate_image\")\n",
    "print(f\"      KOKORO_API_URL={public_url}/generate_audio\")\n",
    "print(\"   3. Restart your local app\")\n",
    "print(\"   4. Generate videos with GPU power!\")\n",
    "print(\"\\nğŸ’¡ Test endpoints:\")\n",
    "print(f\"   Health: {public_url}/health\")\n",
    "print(f\"   Images: {public_url}/generate_image (POST)\")\n",
    "print(f\"   Audio:  {public_url}/generate_audio (POST)\")\n",
    "print(\"\\nâš ï¸  Keep this notebook running! Closing it will stop the server.\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Start Flask server (this will block - server runs forever)\n",
    "app.run(port=5000, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
