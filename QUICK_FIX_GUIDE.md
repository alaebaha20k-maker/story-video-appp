# âš¡ QUICK FIX GUIDE - Critical Issues Only
## Fix the most important problems in 1-2 hours

---

## ðŸ”¥ CRITICAL FIX #1: Security - Remove Exposed API Keys

### **Problem:**
Your Gemini API keys are hardcoded and public in the repo!

### **Fix NOW:**

**Step 1: Create `.env` file**
```bash
cd /home/user/story-video-appp/story-video-generator
cat > .env << 'EOF'
# Gemini API Keys
GEMINI_API_KEY_PRIMARY=AIzaSyC9H-CJ_3l6AtLiajTgS5QR6vANs2Bd19k
GEMINI_API_KEY_SECONDARY=AIzaSyC3lCI117uyVbJkFOXI6BffwlUCLSdYIH0

# Other APIs (optional)
TOGETHER_API_KEY=your_key_here
FAL_API_KEY=your_key_here
PEXELS_API_KEY=your_key_here
EOF
```

**Step 2: Update `api_manager.py`**
```python
# File: src/utils/api_manager.py
def __init__(self):
    self.keys = {
        'gemini': os.getenv('GEMINI_API_KEY_PRIMARY'),  # âœ… From .env
        'gemini_secondary': os.getenv('GEMINI_API_KEY_SECONDARY'),
        'together': os.getenv('TOGETHER_API_KEY'),
        'fal': os.getenv('FAL_API_KEY'),
        'pexels': os.getenv('PEXELS_API_KEY')
    }
```

**Step 3: Add to `.gitignore`**
```bash
echo ".env" >> /home/user/story-video-appp/.gitignore
```

**Step 4: Remove from git history (if already committed)**
```bash
git filter-branch --force --index-filter \
  "git rm --cached --ignore-unmatch story-video-generator/.env" \
  --prune-empty --tag-name-filter cat -- --all
```

---

## ðŸ”¥ CRITICAL FIX #2: Auto-Captions (TikTok Style)

### **Problem:**
Frontend sends `auto_captions: true` but backend does nothing!

### **Fix:**

**Step 1: Install dependencies**
```bash
pip install whisper-timestamped moviepy
```

**Step 2: Create caption generator**

Create file: `story-video-generator/src/editor/caption_generator.py`

```python
"""
ðŸŽ¯ AUTO-CAPTIONS - TikTok-style word-by-word captions
"""

import subprocess
import json
from pathlib import Path
from typing import List, Dict

class CaptionGenerator:
    """Generate TikTok-style captions with word timing"""

    def generate_word_timestamps(self, audio_path: str, script_text: str) -> List[Dict]:
        """Generate word-level timestamps from audio"""

        # Use FFmpeg to extract timing from audio duration
        # Split script into words
        words = script_text.split()

        # Get audio duration
        cmd = [
            'ffprobe', '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'json', audio_path
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        data = json.loads(result.stdout)
        duration = float(data['format']['duration'])

        # Calculate timing per word (simple approach)
        time_per_word = duration / len(words)

        timestamps = []
        current_time = 0.0

        for word in words:
            timestamps.append({
                'word': word,
                'start': current_time,
                'end': current_time + time_per_word
            })
            current_time += time_per_word

        return timestamps

    def create_caption_overlay(
        self,
        timestamps: List[Dict],
        video_width: int = 1920,
        video_height: int = 1080
    ) -> str:
        """Create FFmpeg drawtext filter for word-by-word captions"""

        filters = []

        for i, ts in enumerate(timestamps):
            word = ts['word'].replace("'", "\\'").replace('"', '\\"')
            start = ts['start']
            end = ts['end']

            # TikTok-style: center, large, bold, with background
            filter_text = (
                f"drawtext="
                f"text='{word}':"
                f"fontfile=/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf:"
                f"fontsize=72:"
                f"fontcolor=white:"
                f"borderw=4:"
                f"bordercolor=black:"
                f"x=(w-text_w)/2:"
                f"y=h-150:"  # Bottom of screen
                f"enable='between(t,{start},{end})'"
            )
            filters.append(filter_text)

        # Combine all filters
        return ','.join(filters) if filters else None


caption_generator = CaptionGenerator()
```

**Step 3: Update FFmpeg compiler**

Update file: `story-video-generator/src/editor/ffmpeg_compiler.py`

```python
def create_video(
    self,
    image_paths: List[Path],
    audio_path: Path,
    output_path: Path,
    durations: List[float],
    zoom_effect: bool = True,
    auto_captions: bool = False,  # âœ… NEW
    script_text: str = None  # âœ… NEW
):
    """Create video with FFmpeg - now with auto-captions!"""

    # ... existing concat file code ...

    # Build video filter
    filters = []

    # Base filter: scale and zoom
    if zoom_effect:
        filters.append(
            "scale=1920:1080,"
            "zoompan=z='min(zoom+0.0015,1.1)':d=1:"
            "x=iw/2-(iw/zoom/2):y=ih/2-(ih/zoom/2):s=1920x1080,"
            "fps=24"
        )
    else:
        filters.append('scale=1920:1080,fps=24')

    # Add captions if enabled
    if auto_captions and script_text:
        from src.editor.caption_generator import caption_generator

        timestamps = caption_generator.generate_word_timestamps(
            str(audio_path),
            script_text
        )
        caption_filter = caption_generator.create_caption_overlay(timestamps)

        if caption_filter:
            filters.append(caption_filter)

    video_filter = ','.join(filters)

    # FFmpeg command
    cmd = [
        'ffmpeg',
        '-f', 'concat',
        '-safe', '0',
        '-i', str(concat_file),
        '-i', str(audio_path),
        '-vf', video_filter,
        '-c:v', 'libx264',
        '-preset', 'ultrafast',
        '-crf', '23',
        '-c:a', 'aac',
        '-b:a', '192k',
        '-shortest',
        '-y',
        str(output_path)
    ]

    subprocess.run(cmd, check=True)
    concat_file.unlink()
    return output_path
```

**Step 4: Update API server to pass captions**

Update file: `api_server.py` line 455

```python
video_path = compiler.create_video(
    image_paths,
    str(audio_path),
    Path(f"output/videos/{output_filename}"),
    durations,
    zoom_effect=zoom_effect,
    auto_captions=data.get('auto_captions', False),  # âœ… NEW
    script_text=script_text  # âœ… NEW
)
```

---

## ðŸ”¥ CRITICAL FIX #3: Configurable Zoom Effect

### **Problem:**
Zoom is hardcoded to 0.0015, but you want user to control it (e.g., "5% zoom").

### **Fix:**

**Update `ffmpeg_compiler.py`:**

```python
def create_video(
    self,
    image_paths: List[Path],
    audio_path: Path,
    output_path: Path,
    durations: List[float],
    zoom_effect: bool = True,
    zoom_intensity: float = 5.0,  # âœ… NEW: Percentage (1-10%)
    auto_captions: bool = False,
    script_text: str = None
):
    """Create video with configurable zoom"""

    # ... existing code ...

    if zoom_effect:
        # Convert percentage to zoom rate
        # 5% zoom over average image duration
        avg_duration = sum(durations) / len(durations) if durations else 5.0
        zoom_rate = (zoom_intensity / 100) / avg_duration
        max_zoom = 1.0 + (zoom_intensity / 100)

        video_filter_parts = (
            "scale=1920:1080,"
            f"zoompan=z='min(zoom+{zoom_rate},{max_zoom})':d=1:"
            "x=iw/2-(iw/zoom/2):y=ih/2-(ih/zoom/2):s=1920x1080,"
            "fps=24"
        )
        filters.append(''.join(video_filter_parts))
    else:
        filters.append('scale=1920:1080,fps=24')
```

**Update API server:**

```python
# In api_server.py, line 345 and 673
zoom_intensity = float(data.get('zoom_intensity', 5.0))  # Default 5%

video_path = compiler.create_video(
    image_paths,
    str(audio_path),
    Path(f"output/videos/{output_filename}"),
    durations,
    zoom_effect=zoom_effect,
    zoom_intensity=zoom_intensity,  # âœ… NEW
    auto_captions=data.get('auto_captions', False),
    script_text=script_text
)
```

**Update frontend (GeneratorPage.tsx):**

```typescript
// Add to request body
zoom_intensity: store.zoomIntensity || 5.0,
```

**Add to Zustand store:**

```typescript
// In store/useVideoStore.ts
zoomIntensity: 5.0,
setZoomIntensity: (value: number) => set({ zoomIntensity: value }),
```

---

## ðŸ”¥ CRITICAL FIX #4: Backend Read All Frontend Options

### **Problem:**
Backend ignores `hook_intensity`, `pacing`, `image_mode`, etc.

### **Fix:**

**Update `api_server.py` line 232:**

```python
def generate_video_background(data):
    """Generate video with ALL user options"""
    global progress_state

    try:
        print(f"\nðŸŽ¬ Starting generation: {data.get('topic', 'Untitled')}")

        # âœ… READ ALL OPTIONS
        topic = data.get('topic', 'Untitled')
        story_type = data.get('story_type') or data.get('storytype', 'scary_horror')
        duration = int(data.get('duration', 10))
        num_scenes = int(data.get('num_scenes', 10))
        image_style = data.get('image_style', 'cinematic_film')
        image_mode = data.get('image_mode', 'ai_generated')
        voice_id = get_voice_id(data.get('voice_id'))
        voice_speed = float(data.get('voice_speed', 1.0))
        zoom_effect = data.get('zoom_effect', True)
        zoom_intensity = float(data.get('zoom_intensity', 5.0))
        auto_captions = data.get('auto_captions', False)
        color_filter = data.get('color_filter', 'none')
        hook_intensity = data.get('hook_intensity', 'high')
        pacing = data.get('pacing', 'dynamic')

        print(f"ðŸ“Š Settings:")
        print(f"   Story Type: {story_type}")
        print(f"   Duration: {duration} min")
        print(f"   Scenes: {num_scenes}")
        print(f"   Image Style: {image_style}")
        print(f"   Image Mode: {image_mode}")
        print(f"   Voice: {voice_id} @ {voice_speed}x")
        print(f"   Zoom: {'ON' if zoom_effect else 'OFF'} ({zoom_intensity}%)")
        print(f"   Captions: {'ON' if auto_captions else 'OFF'}")
        print(f"   Filter: {color_filter}")
        print(f"   Hook Intensity: {hook_intensity}")
        print(f"   Pacing: {pacing}")

        # Update progress state
        progress_state['voice_engine'] = 'edge'
        progress_state['voice_id'] = voice_id

        # ... rest of generation ...
```

---

## âœ… TESTING YOUR FIXES

**Step 1: Restart backend**
```bash
cd /home/user/story-video-appp/story-video-generator
python api_server.py
```

**Step 2: Test in frontend**
```bash
cd /home/user/story-video-appp/project-bolt-sb1-nqwbmccj/project
npm run dev
```

**Step 3: Generate a test video**
- Topic: "Test video"
- Enable auto-captions: âœ…
- Zoom intensity: 8%
- Duration: 1 minute

**Step 4: Verify**
- âœ… Video has word-by-word captions
- âœ… Zoom is more pronounced (8% vs old 0.15%)
- âœ… Backend logs show ALL settings being used
- âœ… No API key errors

---

## ðŸŽ¯ SUMMARY OF FIXES

| Issue | Fix | Time | Priority |
|-------|-----|------|----------|
| **Exposed API keys** | Move to `.env` | 5 min | ðŸ”´ Critical |
| **No auto-captions** | Add caption generator | 30 min | ðŸ”´ Critical |
| **Fixed zoom** | Make configurable | 10 min | ðŸŸ¡ High |
| **Ignored options** | Read all frontend data | 15 min | ðŸŸ¡ High |

**Total time: ~1 hour**

---

## ðŸš€ NEXT STEPS AFTER QUICK FIXES

Once these 4 critical fixes are done, you can optionally:

1. Add color filters (10 min)
2. Implement Gemini Server 2 (2 hours)
3. Add SRT subtitle export (15 min)
4. Emotion-based caption colors (20 min)
5. Ken Burns variety (different zoom styles) (30 min)

**But these 4 fixes will make your system:**
- âœ… Secure
- âœ… Fully functional with captions
- âœ… User-controllable zoom
- âœ… Using all frontend options

---

**Want me to implement these fixes now?** Just say:
- **"Apply all quick fixes"** - I'll make all changes
- **"Fix security only"** - Just the .env changes
- **"Show me how to test"** - Testing guide
